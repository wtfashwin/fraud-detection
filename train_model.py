import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE
import joblib

def main():
    print("ğŸ“¥ Loading dataset...")
    # Change this path if your CSV is somewhere else
    df = pd.read_csv("data/creditcard.csv")  

    print("ğŸ” Checking missing values...")
    print(df.isnull().sum())

    print("ğŸ”„ Scaling features...")
    # Features to scale - exclude 'Class' and 'Time' optionally
    features = df.drop(columns=["Class", "Time"])
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)

    print("ğŸ”€ Preparing final dataset...")
    X = scaled_features
    y = df["Class"].values

    print("ğŸ”€ Splitting dataset (Train 80% / Test 20%)...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y
    )

    print(f"âš ï¸ Class balance before SMOTE â†’ {np.bincount(y_train)}")

    print("ğŸ¤– Applying SMOTE to balance classes...")
    smote = SMOTE(random_state=42)
    X_res, y_res = smote.fit_resample(X_train, y_train)

    print(f"âœ… Class balance after SMOTE â†’ {np.bincount(y_res)}")

    print("ğŸ’¾ Saving preprocessed arrays and scaler...")
    np.savez_compressed(
        "preprocessed_data.npz",
        X_res=X_res,
        y_res=y_res,
        X_test=X_test,
        y_test=y_test
    )
    joblib.dump(scaler, "scaler.joblib")

    print("ğŸ Preprocessing complete.")

if __name__ == "__main__":
    main()
